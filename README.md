# ğŸ“ OCR for Tamil LLM Training

This project evaluates multiple **Optical Character Recognition (OCR)** engines for **Tamil text extraction** from scanned PDFs. The goal is to build a reliable pipeline to support **training Large Language Models (LLMs)** in Tamil by ensuring high-quality text extraction from real-world documents.

---

## ğŸ¯ Objective

To **compare and benchmark** different OCR engines for **Tamil script recognition**, with a focus on:

- ğŸ“ˆ Accuracy  
- ğŸ§± Layout retention  
- ğŸ§© Handling complex Tamil scripts and ligatures  

---

## ğŸ”„ Pipeline Overview

### 1. ğŸ“¥ Upload PDF  
Users provide scanned Tamil-language PDF documents.

### 2. ğŸ–¼ï¸ Convert PDF to Images  
Each page is converted into high-resolution images using `pdf2image`.

### 3. ğŸ” Apply OCR Engines  
Multiple OCR tools are run on each image:
- **Tesseract OCR** (with Tamil language pack)
- **PaddleOCR**
- **EasyOCR**

### 4. ğŸ’¾ Extract & Store Text  
Recognized text is saved in `.txt` and optionally `.json` format for further analysis.  
Each OCR engineâ€™s results are saved **separately for comparison**.

---

## ğŸ§° Tools & Libraries Used

| Component           | Tool / Library       |
|---------------------|----------------------|
| PDF to Image        | `pdf2image`          |
| OCR Engine 1        | `Tesseract-OCR`      |
| OCR Engine 2        | `PaddleOCR`          |
| OCR Engine 3        | `EasyOCR`            |
| Image Processing    | `OpenCV`, `PIL`      |
| Output Formats      | `.txt`, `.json`      |

---

## ğŸ“Š Evaluation Metrics

To compare OCR engines, the following metrics are used:

- âœ… **Character-Level Accuracy**
- âœ… **Word-Level Accuracy**
- âŒ **Error Analysis**: missed characters, incorrect glyphs
- ğŸ”¤ **Support for complex Tamil ligatures and words**

---

## ğŸ“ Output 
The output generated by the OCR pipeline will be in either text (.txt) or JSON (.json) format, depending on the use case. It contains the extracted content page by page, and for documents with multi-column layouts, the text is also segmented column by column to preserve the original reading order and structure. This ensures accurate and organized data for downstream processing or model training.

---
## Future Work
Integration of layout-aware OCR using tools like LayoutParser or MarkItDown
Visual comparison of OCR outputs across engines
Incorporation of word-level confidence scores
Creation of a benchmarking dashboard for evaluation metrics
## Next Big Step

The upcoming phase of this project involves automatic detection of structural elements in scanned documents, such as:

- Tables  
- Images  
- Multi-column layouts  
- Section headers and footers  

These elements will be detected using advanced layout parsing tools like:

- LayoutParser  
- Donut (Document Understanding Transformer)  
- DocTR  
- PaddleLayout  

This will enable structured and intelligent document parsing, significantly improving dataset quality for downstream Tamil LLM training.

---

## Web Scraping

In addition to OCR-based extraction, this project includes a **web scraping module** designed to extract Tamil text content directly from URLs. The scraper recursively visits a given webpage, collects all visible text (including from linked pages), and saves the extracted content for further processing. This is particularly useful for gathering Tamil data from news sites, educational portals, and public documentsâ€”helping build a richer dataset for Tamil LLM training.

---

## Author

**Risab S**

## âš™ï¸ Setup Instructions

```bash
# Install Python dependencies
pip install pdf2image pytesseract easyocr paddleocr

# Install Tesseract OCR with Tamil support (Linux)
sudo apt install tesseract-ocr tesseract-ocr-tam

pip install pdf2image pytesseract easyocr paddleocr
sudo apt install tesseract-ocr tesseract-ocr-tam

